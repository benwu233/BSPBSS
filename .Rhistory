mll = rep(0,25)
for(lr0 in c(0.002,0.004,0.006,0.008,0.01)){
for(decay0 in c(0.002,0.004,0.006,0.008,0.01)){
tmp = res_sum_list[[tag]]$loglik[200:500]
print( paste(lr0, decay0, tag, effectiveSize(tmp),mean(tmp)) )
mll[tag] = mean(tmp)
tag = tag + 1
}
}
plot(res_sum_list[[1]]$loglik)
plot(res_sum_list[[25]]$loglik)
plot(res_sum_list[[24]]$loglik)
plot(res_sum_list[[23]]$loglik)
plot(res_sum_list[[2]]$loglik)
plot(res_sum_list[[3]]$loglik)
plot(res_sum_list[[4]]$loglik)
plot(res_sum_list[[5]]$loglik)
plot(res_sum_list[[6]]$loglik)
plot(res_sum_list[[7]]$loglik)
plot(res_sum_list[[8]]$loglik)
plot(res_sum_list[[10]]$loglik)
plot(res_sum_list[[1]]$loglik)
plot(res_sum_list[[5]]$loglik)
plot(res_sum_list[[4]]$loglik)
plot(res_sum_list[[6]]$loglik)
mean(res_sum_list[[6]]$loglik[200:500])
mean(res_sum_list[[6]]$loglik[200:500]) - mean(res_sum_list[[1]]$loglik[200:500])
plot(res_sum_list[[20]]$loglik)
plot(res_sum_list[[18]]$loglik)
plot(res_sum_list[[17]]$loglik)
plot(res_sum_list[[16]]$loglik)
plot(res_sum_list[[20]]$loglik)
plot(res_sum_list[[21]]$loglik)
plot(res_sum_list[[22]]$loglik)
plot(res_sum_list[[23]]$loglik)
plot(res_sum_list[[24]]$loglik)
plot(res_sum_list[[14]]$loglik)
plot(res_sum_list[[13]]$loglik)
plot(res_sum_list[[11]]$loglik)
plot(res_sum_list[[6]]$loglik)
plot(res_sum_list[[7]]$loglik)
mean(res_sum_list[[6]]$loglik[200:500]) - mean(res_sum_list[[7]]$loglik[200:500])
plot(res_sum_list[[5]]$loglik)
mean(res_sum_list[[6]]$loglik[200:500]) - mean(res_sum_list[[25]]$loglik[200:500])
plot(res_sum_list[[6]]$loglik[200:500])
library(BSPBSS)
library(ica)
library(oro.nifti)
library(neurobase)
library(coda)
library(RandomFieldsUtils)
library(PrevMap)
library(BayesGPfit)
#path0 = "/Users/ben/desktop/work2/GaussianProcess/real_kernel/"
path0 = "/home/ben/work/bspbss/real_kernel/"
## real data
#load("/Users/ben/desktop/work3/data/abide_3mm.RData")
load("/home/ben/data/abide_3mm.RData")
d0 = 0.5
mask1 = rep(0, nrow(coord))
coord0 = as.matrix(coord)
for(i in 1:nrow(coord)){
mask1[i] = aal_map[coord0[i,][1],coord0[i,][2],coord0[i,][3]]
}
rm(falff)
rm(lfcd)
rm(reho)
gc()
nii = readNIfTI('/home/ben/data/AAL_90_3mm.nii')
#path0 = "/Users/ben/desktop/work2/GaussianProcess/real_kernel/"
path0 = "/home/ben/work/bspbss/real_kernel/"
#savepath = "/Users/ben/desktop/work2/GaussianProcess/real_kernel/res/"
savepath = "/home/ben/work/bspbss/real_kernel/"
res_sum_list=list()
for(i in 1:5){
print(i)
ini = readRDS(paste0(path0,"ini_gk002_82_lr0.004de0.002_noise",i,".rds"))
res = readRDS( (paste0(path0,"res_gk002_82_20k_lr0.004de0.002_noise",i,".rds") ) )
res_sum = sum_mcmc_bspbss(res, degree_weighted, ini$kernel, start = 1, end = 2000, select_p = 0.95)
res_sum_list[[i]] = res_sum
saveRDS(res_sum,paste0(path0,"res_sum_gk002_82_20k_b0k_lr0.004de0.002_noise",i,".rds") )
}
plot(res_sum_list[[1]]$loglik)
plot(res_sum_list[[2]]$loglik)
plot(res_sum_list[[3]]$loglik)
plot(res_sum_list[[4]]$loglik)
plot(res_sum_list[[5]]$loglik)
plot(res_sum_list[[5]]$loglik[100:2000])
plot(res_sum_list[[4]]$loglik[100:2000])
rm(list=ls())
gc()
#load("/Users/ben/desktop/work3/data/abide_3mm.RData")
load("/home/ben/data/abide_3mm.RData")
d0 = 0.5
mask1 = rep(0, nrow(coord))
coord0 = as.matrix(coord)
for(i in 1:nrow(coord)){
mask1[i] = aal_map[coord0[i,][1],coord0[i,][2],coord0[i,][3]]
}
rm(falff)
rm(lfcd)
rm(reho)
gc()
MClength = 3000
burn_in = 0
show_step = 1000
for(lr0 in c(0.001,0.01,0.1)){
for(decay0 in c(0.001,0.01,0.1)){
seed0 = lr0*10000 + decay0 * 100
set.seed(seed0)
print(paste(seed0,lr0,decay0))
ini = init_bspbss(degree_weighted, mask = (mask1>0), xgrid = coord, dens = d0, q = 10, kernel="gaussian",ker_par = c(0.02,82), num_eigen = 500)
path0 = "/home/ben/work/bspbss/real_kernel/"
saveRDS(ini,paste0(path0,"ini_gk002_82_lr",lr0,"de",decay0,".rds") )
res = mcmc_bspbss(degree_weighted,ini$init,ini$prior,ini$kernel,ep=0.5,lr = lr0,decay=decay0,subsample_n = 0.05, subsample_p = 0.005,MClength,burn_in,thin=10,show_step)
saveRDS(res,paste0(path0,"res_gk002_82_3k_lr",lr0,"de",decay0,".rds") )
res_sum = sum_mcmc_bspbss(res, degree_weighted, ini$kernel, start = 1, end = 300, select_p = 0.95)
saveRDS(res_sum,paste0(path0,"res_sum_gk002_82_3k_lr",lr0,"de",decay0,".rds") )
}
}
res_sum_list=list()
tag = 1
for(lr0 in c(0.001,0.01,0.1)){
for(decay0 in c(0.001,0.01,0.1)){
res_sum_list[[tag]] = readRDS(paste0(path0,"res_sum_gk002_82_3k_lr",lr0,"de",decay0,".rds"))
tag = tag + 1
}
}
tag = 1
mll = rep(0,9)
for(lr0 in c(0.001,0.01,0.1)){
for(decay0 in c(0.001,0.01,0.1)){
tmp = res_sum_list[[tag]]$loglik[200:500]
print( paste(lr0, decay0, tag, effectiveSize(tmp),mean(tmp)) )
mll[tag] = mean(tmp)
tag = tag + 1
}
}
tag = 1
mll = rep(0,9)
for(lr0 in c(0.001,0.01,0.1)){
for(decay0 in c(0.001,0.01,0.1)){
tmp = res_sum_list[[tag]]$loglik
print( paste(lr0, decay0, tag, effectiveSize(tmp),mean(tmp)) )
mll[tag] = mean(tmp)
tag = tag + 1
}
}
plot(res_sum_list[[tag]]$loglik)
plot(res_sum_list[[1]]$loglik)
plot(res_sum_list[[2]]$loglik)
plot(res_sum_list[[3]]$loglik)
plot(res_sum_list[[4]]$loglik)
plot(res_sum_list[[5]]$loglik)
plot(res_sum_list[[6]]$loglik)
plot(res_sum_list[[7]]$loglik)
plot(res_sum_list[[8]]$loglik)
plot(res_sum_list[[9]]$loglik)
plot(res_sum_list[[7]]$loglik)
plot(res_sum_list[[7]]$loglik[100:300])
plot(res_sum_list[[8]]$loglik[100:300])
plot(res_sum_list[[1]]$loglik[100:300])
plot(res_sum_list[[2]]$loglik[100:300])
lr0 = 0.004
decay0 = 0.002
res_sum = readRDS(paste0(path0,"res_sum_gk002_82_40k_b10k_lr",lr0,"de",decay0,".rds"))
decay0
res_sum = readRDS( paste0(path0,"res_sum_gk002_82_40k_b10k_lr",lr0,"de",decay0,".rds") )
rm(list=ls())
gc()
res_sum = readRDS( paste0(path0,"res_sum_gk002_82_40k_b10k_lr",lr0,"de",decay0,".rds") )
path0 = "/home/ben/work/bspbss/real_kernel/"
lr0 = 0.004
decay0 = 0.002
res_sum = readRDS( paste0(path0,"res_sum_gk002_82_40k_b10k_lr",lr0,"de",decay0,".rds") )
res_sum = readRDS( paste0(path0,"res_gk002_82_40k_b10k_lr",lr0,"de",decay0,".rds") )
res_sum = readRDS( paste0(path0,"res_gk002_82_40k_lr",lr0,"de",decay0,".rds") )
res_sum
paste0(path0,"res_gk002_82_40k_lr",lr0,"de",decay0,".rds")
res_sum = readRDS( paste0(path0,"res_gk002_82_40k_lr",lr0,"de",decay0,".rds") )
res_sum0 = readRDS( paste0(path0,"res_gk002_82_40k_lr",lr0,"de",decay0,".rds") )
res_sum0
res_sum0 = readRDS( paste0(path0,"res_gk002_82_40k_lr",lr0,"de",decay0,".rds") )
paste0(path0,"res_sum_gk002_82_40k_b10k_lr",lr0,"de",decay0,".rds")
sessionInfo()
sessionInfo()
library(BSPBSS)
library(BSPBSS)
install.packages( c("movMF", "rstiefel", "glmnet", "BayesGPfit", "svd", "RandomFieldsUtils", "neurobase", "oro.nifti") )
install.packages("neurobase")
install.packages('neurobase')
install.packages("neurobase", dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('neurobase',repos='http://cran.us.r-project.org')
?copyNIfTIHeader
library(oro.nifti)
?copyNIfTIHeader
1200*2/4.18
install.packages("neurobase")
library(BSPBSS)
library(BSPBSS)
quantile(rnorm(10),0)
a = rnorm(10)
a
quantile(a,0)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
install.packages("testthat")
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
install.packages("BSPBSS")
install.packages("BSPBSS")
install.packages("BSPBSS")
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
set.seed(612)
sim = sim_2Dimage(length = 30, sigma = 5e-4, n = 30, smooth = 6)
levelplot2D(sim$S,lim = c(-0.04,0.04), sim$coords)
ini = init_bspbss(sim$X, sim$coords, q = 3, ker_par = c(0.1,50), num_eigen = 50)
res = mcmc_bspbss(ini$X,ini$init,ini$prior,ini$kernel,n.iter=20,n.burn_in=1000,thin=10,show_step=100)
res_sum = sum_mcmc_bspbss(res, ini$X, ini$kernel, start = 101, end = 200, select_p = 0.5)
install.packages("BSPBSS")
install.packages("BSPBSS")
install.packages("BSPBSS")
install.packages("BSPBSS")
install.packages("BSPBSS")
install.packages("BSPBSS")
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
usethis::use_vignette("BSPBSS-vignette")
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
install.packages("BSPBSS")
install.packages("BSPBSS")
23400/72
37800/120
53100/180
10888/30
23400/75
365*0.75
365*0.75/60
rgamma(1,1,1)
library(BSPBSS)
?pre_nii
?levelplot2D
library(neurobase)
?readNIfTI2
library(BSPBSS)
?sim_2Dimage
library(BSPBSS)
?sim_2Dimage
install.packages("testthat")
library(BSPBSS)
?sim_2Dimage
library(BSPBSS)
?levelplot2D
library(BSPBSS)
?mcmc_bspbss
library(BSPBSS)
?sum_mcmc_bspbss
library(BSPBSS)
?BSPBSS
?BSPBSS
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
library(BSPBSS)
install.packages(BSPBSS)
install.packages("BSPBSS")
install.packages("BSPBSS")
install.packages("BSPBSS")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
2+3
?knitr::opts_chunk
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1.csv")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1.csv")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1.csv", fileEncoding = "UTF-8")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1.csv", encoding = "UTF-8")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1.csv", encoding = "UTF-16")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1_test.csv", encoding = "UTF-16")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example_1_test.csv", encoding = "UTF-16")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1_test.csv", encoding = "UTF-16")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1_test.csv")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1.csv")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1.csv",encoding='UTF-8')
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1.csv",header = TRUE,as.is = TRUE,encoding='UTF-8')
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1_test.csv",encoding='UTF-8')
table1_1
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1_test.csv")
table1_1
x = 1
y = example1_1
hist(d,prob=TRUE,col="green")
d = rnorm(100)
hist(d,prob=TRUE,col="green")
hist(d,col="green")
install.packages("car")
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1_utf8.csv")
library(dplyr)
arrange(table1_1,姓名)
arrange(table1_1,desc(数学))
table1_1[order(table1_1$姓名),]
table1_1
a<-c("金融","地产","医药","医药","金融","医药")
f1 = factor(a)
f1
as.numeric(f1)
b<-c("很好","好","一般","差","很差")
f2<-factor(b,ordered=TRUE,levels=c("很好","好","一般","差","很差"))
as.numeric(f2)
f2
save(table1_1,"/Users/ben/desktop/stat/example/chap01/test.RData")
save(table1_1,file="/Users/ben/desktop/stat/example/chap01/test.RData")
rm(list=ls())
load("/Users/ben/desktop/stat/example/chap01/test.RData")
mat<-as.matrix(table1_1[,2:4])
as.data.frame(mat)
library(reshape2)
tab.long<-melt(table1_1,id.vars="姓名",variable.name="课程",value.name="分数")
tab.long
table1_3 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_3_utf8.csv")
tab.long<-melt(table1_3,variable.name="课程",value.name="分数")
tab.long
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1_utf8.csv")
table1_1
table1_1 = rbind(table1_1,table1_1)
table1_1
tab.long<-melt(table1_1,id.vars="姓名",variable.name="课程",value.name="分数")
tab.long
table1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/table1_1_utf8.csv")
tab.long<-melt(table1_1,id.vars="统计学",variable.name="课程",value.name="分数")
tab.long
table1_1
library(tidyr)
df1<-gather(table1_1,key="课程",value="分数","统计学","数学","经济学")
df1
df1<-gather(table1_1,key="课程",value="分数")
df1
example1_1 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_1_utf8.csv")
attach(example1_1)
?attach
mytable1<-table(态度,社区);
mytable1
table(example1_1$社区)
table(example1_1$社区,example1_1$态度)
table(example1_1$社区,example1_1$态度,example1_1$性别)
addmargins(mytable1)
addmargins(prop.table(mytable1)*100)  # 将列联表转换成百分比表
mytable2<-ftable(example1_1,row.vars=c("性别","态度"),col.vars="社区")
mytable2
ftable(addmargins(table(example1_1$性别,example1_1$态度,example1_1$社区)))
?ftable
addmargins(table(example1_1$性别,example1_1$态度,example1_1$社区))
ftable(example1_1,row.vars=c("社区"),col.vars=c("性别","态度"))
library(vcd)
install.packages("vcd")
library(vcd)
structable(性别+态度~社区,data=example1_1) # 不同表达式产生不同形式的多维表
structable(example1_1)
library(DescTools)
mytable<-ftable(example1_1)
df<-Untable(mytable)
df
Untable(table(example1_1))
table(example1_1)
ftable(example1_1)
tab<-ftable(example1_1)
df<-as.data.frame(tab);df
example1_2 = read.csv("/Users/ben/desktop/stat/example/chap01/example1_2_utf8.csv")
tab = Freq(example1_2)
tab
tab = Freq(example1_2$销售额)
tab
par(mai=c(0.6,0.6,0.4,0.4),cex=0.7)
set.seed(2025)
x <- rnorm(200)
y <- 1+2*x +rnorm(200)
d<-data.frame(x,y)
plot(d,xlab="x=自变量",ylab="y=因变量")
grid(col="grey60")
axis(side=4,col.ticks="blue",lty=1)
grid(col="grey60")
axis(side=40,col.ticks="blue",lty=1)
axis(side=4,col.ticks="blue",lty=2)
plot(d,xlab="x=自变量",ylab="y=因变量")
grid(col="grey60")
axis(side=4,col.ticks="blue",lty=1)
axis(side=2,col.ticks="blue",lty=1)
axis(side=1,col.ticks="blue",lty=1)
axis(side=3,col.ticks="blue",lty=1)
axis(side=3,col.ticks="blue",lty=100)
polygon(d[chull(d),],lty=6,lwd=1,col="lightgreen")
points(d)
points(mean(x),mean(y),pch=19,cex=5,col=2)
abline(v=mean(x),h=mean(y),lty=2,col="gray30")
abline(lm(y~x),lwd=2,col=2)
lines(lowess(y ~ x,f=1/6),col=4,lwd=2,lty=6)
segments(-0.8,0,-1.6,3.3,lty=6,col="blue")
arrows(0.45,-2.2,-0.8,-0.6,code=2,angle=25,length=0.06,col=2)
text(-2.2,3.5,labels=expression("拟合的曲线"),adj=c(-0.1,0.02),col=4)
text(-2.2,3.5,labels=expression("fitted"),adj=c(-0.1,0.02),col=4)
rect(0.4, -1.6, 1.8,-3,col="pink",border="grey60")
mtext(expression(hat(y)==hat(beta)[0]+hat(beta)[1]*x),cex=0.9,side=1,line=-2.5,adj=0.7)                         # 添加注释表达式
legend("topleft",legend=c("拟合的直线","拟合的曲线"),lty=c(1,6),col=c(2,4),cex=0.8,fill=c("red","blue"),box.col="grey60",ncol=1,inset=0.02)            # 添加图例
title("散点图及拟合直线和曲线\n并为图形增加新的元素",cex.main=1,font.main=4)   # 增加标题并折行,使用斜体字
box(col=4,lwd=2)
par(mfrow=c(2,2),mai=c(0.4,0.4,0.3,0.1),cex=0.7,mgp=c(2,1,0),cex.axis=0.8,cex.main=0.8,font.main=1)
set.seed(123)         # 设置随机数种子
x<-rnorm(100) # 生成100个标准正态分布随机数
y<-rexp(100) # 生成100个指数分布随机数
plot(x,y,col=sample(c("black","red","blue"),100,replace=TRUE),main="(a) 散点图")
boxplot(x,y,col=2:3,main="(b) 箱线图")
hist(x,col="orange1",ylab="y",main="(c) 直方图")
barplot(runif(5,10,20),col=2:6,main="(d) 条形图")
layout(matrix(c(1,2,3,3),nrow=2,ncol=2,byrow=TRUE),heights=c(2,1))
layout.show(3)
layout(matrix(c(1,2,3,3),nrow=2,ncol=2),heights=c(2,1))
layout.show(3)
layout(matrix(c(1,1,1,2,3,4),nrow=2,ncol=3,byrow=TRUE),widths=c(3:1),heights=c(2,1))
layout.show(4)
layout(matrix(c(1,2,3,4,5,5,6,7,8),3,3,byrow=TRUE),widths=c(2:1),heights=c(1:1))
layout.show(8)
？layout.show
?layout.show
layout(matrix(c(1,1,1,2,3,4),nrow=2,ncol=3,byrow=TRUE),widths=c(3:1),heights=c(2,1))
layout.show(4)
layout(matrix(c(1,1,1,2,3,4),nrow=2,ncol=3,byrow=TRUE),widths=c(3:1),heights=c(2,1))
layout.show(3)
layout(matrix(c(1,1,1,2,3,4),nrow=2,ncol=3,byrow=TRUE),widths=c(3:1),heights=c(2,1))
layout.show(2)
n=100;set.seed(12);x<-rnorm(n);y<-rexp(n)
layout(matrix(c(1,2,3,4,5,5,6,7,8),3,3,byrow=TRUE),widths=c(2:1),heights=c(1:1))
par(mai=c(0.3,0.3,0.3,0.1),cex.main=0.9,font.main=1)
barplot(runif(8,1,8),col=2:7,main="(a) 条形图")
pie(1:12,col=rainbow(6),labels="",border=NA,main="(b) 饼图")
qqnorm(y,col=1:7,pch=19,xlab="",ylab="",main="(c) Q-Q图")
plot(x,y,pch=19,col=c(1,2,4),xlab="",ylab="",main="(d) 散点图")
plot(rnorm(25),rnorm(25),cex=(y+2),col=2:4,lwd=2,xlab="",ylab="",main="(e) 气泡图")
plot(density(y),col=4,lwd=1,xlab="",ylab="",main="(f) 核密度图");polygon(density(y),col="gold",border="blue")
hist(rnorm(1000),col=3,xlab="",ylab="",main="(g) 直方图")
boxplot(x,col=2,main="(h) 箱线图")
x<-1:10
a<- LETTERS[1:10]
a
par(mfrow=c(1,2),mai=c(0.4,0.4,0.3,0.2),cex=0.8,cex.axis=0.7,cex.lab=0.8,mgp=c(2,1,0),cex.main=0.9,font.main=1)
barplot(x,names=a,col=c("red","green"),main="(a) 循环使用2种颜色")
barplot(x,names=a,col=1:8,main="(b) 重复使用颜色1:8")
par(mfrow=c(2,3),mai=c(0.3,0.3,0.3,0.1),cex=0.7,mgp=c(1,1,0),cex.axis=0.7,cex.main=1,font.main=1)
x<-1:7
names<-LETTERS[1:7]
barplot(x,names=names,col=rainbow(7),main="col=rainbow()")
barplot(x,names=names,col=rainbow(7,start=0.4,end=0.5),main="col=rainbow(start=0.4,end=0.5)")
barplot(x,names=names,col=heat.colors(7),main="col=heat.colors()")
heat.colors(7)
barplot(x,names=names,col=terrain.colors(7),main="col=terrain.colors()")
barplot(x,names=names,col=topo.colors(7),main="col=topo.colors()")
barplot(x,names=names,col=cm.colors(7),main="col=cm.colors()")
library(RColorBrewer)
par(mfrow=c(2,3),mai=c(0.1,0.3,0.3,0.1),cex=0.6,font.main=1)
palette1<-brewer.pal(7,"Reds")
brewer.pal(7,"Reds")
palette2<-brewer.pal(7,"Set1")            # 7种颜色的离散型调色板
palette3<-brewer.pal(7,"RdBu")            # 7种颜色的红蓝色极端值调色板
palette4<-rev(brewer.pal(7,"Greens"))     # 调色板颜色反转
palette5<-brewer.pal(8,"Spectral")[-1]       # 去掉第1种颜色，使用其余7种
palette6<-brewer.pal(6,"RdYlBu")[2:4]     # 使用其中的2:4种颜色
barplot(1:7,col=palette1,main="(a) 红色连续型调色板")
brewer.pal(6,"RdYlBu")
barplot(1:7,col=palette2,main="(b) 离散型调色板")
barplot(1:7,col=palette3,main="(c) 极端值调色板")
barplot(1:7,col=palette4,main="(d) 调色板颜色反转")
barplot(1:7,col=palette5,main="(e) 去掉第1种颜色")
7/0/636
7/0.636
7/0.455
6/0.455
5/0.455
list0 = read.csv("/Users/ben/desktop/list.csv")
list0 = read.csv("/Users/ben/desktop/list.csv",header = FALSE)
head(list0)
order(list0$V1)
list0[order(list0$V1),]
list1 = list0[order(list0$V1),]
median(list1$V1)
sum(list1$V1<2021200744)
sum(list1$V1>2021200744)
head(Titanic)
class(Titanic)
Titanic
as.data.frame( Titanic )
Untable(Titanic)
library(DescTools)
Untable(Titanic)
t0 =  Untable(Titanic)
